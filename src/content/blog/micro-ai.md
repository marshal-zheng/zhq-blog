---
author: ZHQ
pubDatetime: 2025-07-20T00:00:00+08:00
title: '微软ai课程'
featured: false
draft: false
tags:
  - 'ai-for-beginner'
description: '暂时记录翻译'
---
我是 Carlota Cucho，我是一名专注于人工智能的云技术布道师。这太不可思议了！那么今天，我们来谈谈一些基础知识。你已经开始了——你已经开始了入门介绍。现在，让我们更深入一些。让我们看看如何探索和比较不同的 LLM（大语言模型）。当然，我们现在已经有了 LLM，但如果你想了解一下，我们可以谈很多。

稍后，但我们将稍微谈谈语言模型的比较。所以，从这里开始，你会看到一些关于基础模型、语言模型的内容，稍后 Carlot 会展示一些关于 Azure AI 的东西。那么，你今天会学到什么呢？你可能听说过基础模型，所以让我们来理解一下基础模型、LLM 和语言模型之间的区别。如何对语言模型进行分类，因为它们有很多分类方法。然后 Carlot 会展示一些关于 Azure AI 的内容。让我们先从基础模型与 LLM 开始，但首先，要理解这一点：

让我们从基础模型本身开始。为什么？因为你可能已经看到了很多关于基础模型、Z、L、S 等的信息。你可能对它们的工作原理感到困惑。让我们来稍微思考一下。基础模型的作用如下：通常，它是部署新事物的基础。那么，Pablo，你这是什么意思呢？好吧，让我们这样想：想象一下，我有一个基础模型，我希望你用它来执行多种任务。所以这里我有一个用于教学的模型，你可以放入像多模态数据源来训练它。

它可以包含教学材料、视频、互动和学科内容。然后我们有 CTIC，这样我们就可以有多个助手、学生和教育者来促进学习和教学，还有学科内容。你可以看到我们这里有很多输入；我们用大量的东西进行训练，并且我们可以有很多测试和目标。但你会发现它能做很多事情，对吧，但它可能做得并不完美。我们可能需要指导它们如何作为教育者去做 X 或 Y。

如何评估它们，对吧？因为你没有像说明书一样的东西来理解它是在如何提供帮助。那么它就是基础。为什么？因为它是构建新解决方案的基石。所以这就是它们被称为基础模型的原因。

让我们也用这张图来说明。让我们思考一下。基础模型是由斯坦福大学的研究人员提出的。所以他们是这样使用它的。这里的基础模型非常简单；它们有一些先决条件，需要是预训练的、通用的、适应性强的、大规模的、以及自监督的。你可能在这里看到，基础模型可以涵盖很多东西。

嗯，如果你对 LLM 有所了解，它们满足所有这五个条件，所以是的，LLM 是基础模型，因为它们满足所有这五个条件。然而，并非所有基础模型都是 LLM，因为它们有时不使用语言。正如我所说，它们使用多模态方法，所以它们有一种多模态的方式来解释如何回答问题。它们有时不使用分词器（tokenizers），所以这就是区别所在。所以是的，基础模型非常重要，因为我们的 LLM 是基础模型，但并非所有基础模型都是 LLM。

这太不可思议了，但现在我们理解了这些，我们将开始稍微谈谈我们的语言模型本身。对吧？这就引出了一个经典的讨论：开源与专有。让我们先想想开源。当你有开源时，如今我们有了巨大的发展。很多公司都在做开源语言模型，这非常了不起。但让我们稍微思考一下。那么，这些意味着什么呢？对吧？所以开源通常指的是他们用来训练 LLM 的某些部分的来源。所以想象一下，你有我用来训练的代码，有些提供了权重。如果你不知道，权重基本上是语言模型的微调，这样它就可以深入内部进行研究，甚至提供完整的模型，你只需下载并开始玩耍，你可以调整一切。

这些都非常了不起，但问题在于：其中很多是由研究团体或组织提供的。这些通常没有太多资源，它们应该得到支持和更新，以提供新功能或安全更新——特别是当你考虑到提示注入（prompt injection）等问题时。

你可能会在这里看到，是的，开源非常了不起，但它可能在这里或那里存在一些缺陷，或者它们的许可证对我们想做的事情来说可能不够宽松。所以，开源带来了一系列你需要思考并解决的小问题。

专有选项通常要容易得多；它们已经提供了许多这类服务，当然，如果你使用云服务，这些服务是通过 API 提供的。但专有选项的好处在于，你知道你会得到什么，你知道很多事情都会被正确地完成。所以，你会不断地获得更新。这些模型当然会限制你；它们提供了微调模型的机会，但这通常意味着你将有很多已经可以使用的东西。它是一个已经做好的解决方案，你可以拿来就用。好的，所以你学到了一点关于开源模型和专有模型。如果你问到开源，你有很多选择，对吧？你有 Falcon，你有 Llama，还有 Old Lama。所以，我们有很多选择，而我们的专有选项可以问到，你知道的，ChatGPT。那我为什么这么说呢？因为你注意到我没有谈到嵌入（embeddings），对吧？那么，什么是嵌入呢？

让我们以一个 OpenAI 模型为例，来谈谈它们的分类。

你会注意到它们有非常严格的分类。所以，让我们来看一个将所有东西都转换成嵌入的语言模型。所以，我们有一个字符串。我们有一个提示；你需要有人来沟通。想象一下，你知道我有一种格式，可以用来与不同的模型沟通，对吧？所以，把这个转换成嵌入是非常棒的，因为然后我可以轻松地想象，我可以将它用于像 RAG 这样的系统，我可以在其中存储我所有的嵌入，然后我再次搜索，就能取回我的信息。所以嵌入对于今天的生成式 AI 系统非常重要，而且不仅如此，

它们被用来沟通多种类型的语言系统、语言模型，所以它只是非常简单的将字符串转换为每个人都能理解的嵌入。然后我们有用于图像生成的语言模型，大家都知道的，DALL-E。每个人都已经玩过了，你也可以在 Web 端的 Co-Pilot 上找到。所以我这里有一个提示，你把它放在引号里，然后你把它放入你的生成式 AI 神经网络，然后“砰”，你就会得到一张图片。所以这里你有一幅飞狗的画，这里你有一张令人难以置信的图片。然后是经典的，谁还没用过文本生成呢？对吧？

这里的每个人都曾用它找过乐子。所以你也可以去 Attic Co-Pilot web 以及 JBT。你可以去，甚至去 Hugging Face，对吧？你可以在 Hugging Face 上访问很多其他模型，比如 Falcon, Orama。我们有 MOL，这些都非常了不起。所以基本上，输入一个提示，然后你有提示工程（prompt engineering），你会在这个课程的后面看到。然后生成式 AI 开始写作，然后它生成一段文本。

它可以是文本；也可以是代码。我们当然有一些是为代码优化的，但你可以在这里看到它的工作原理。所以我们通常有这三个更明确定义的类型。当然，如果你想细分，你可以专门化；你可以在这里或那里做很多，你知道的，额外的事情。记住，你总是可以，你知道的，与这些语言模型互动，以及你需要它来做什么，为了你的业务、你的爱好，或任何你想创造的东西。让我们来谈谈服务与模型。还记得我之前谈到的吗，

你可以轻松地在云端访问一些令人难以置信的模型。这正是我这么说的原因。因为那些就是服务。这意味着那些已经，你知道的，在云端启动了。你无法自己改变它们，除非，你知道的，更深入地去尝试对它们进行微调。但基本上，那些都是标准的，它们通常是简单的 API 调用。你只需，你知道的，发送你的提示，然后你就可以得到一个答案。你需要处理可扩展性。

云端的可扩展性取决于你的安全措施实施得有多好。云端的安全性至关重要，所以一切都需要严密和安全。不仅如此，你还可以集成你所有的服务。这就是拥有这样一个服务的优势；它变得更容易操作和调整。

如果你想稍微改变一些东西，你可以，但当然，我们经常对一系列服务进行微调。理解这一点很重要，但这让你能够以一种简单的方式与模型互动。

直接与模型互动可能会有点困难。你需要下载模型，设置它，想象一下你有一台服务器。你需要维护那台服务器，处理可扩展性。想象一下你有多个客户端涌入，所以模型是为直接交互而设计的。

它使直接交互更容易，让你能够理解整个流程是如何工作的。然而，如果你需要与你的云服务交互，你可能会遇到一些挑战，如果没有相应的生态系统，这会变得更加困难。

不过，你拥有更多的控制权，但你也需要处理基础设施成本等问题。现在，我非常感兴趣 Carlot 要分享的内容。

告诉我 Azure AI Studio 是如何工作的。我其实不知道。当然，呃，谢谢，Pablo。嗯，我很乐意向你介绍如何在 Azure 中使用基础模型，特别是在 Studio 中。我在这里要讲的第一个问题是为什么会出现错误。对吧？呃，在基础模型不断发展的格局中，为你的特定场景选择合适的候选模型只是旅程的开始。所以，一旦你确定了你的首选，就该在你的用例上对它们进行测试了。所以，Studio 是你开发、测试和管理 AI 应用程序整个生命周期的一站式平台。事实上，这个平台集成了微软的数据技术，用于优化数据库中的存储和搜索，以及 Pablo 刚刚介绍的各种专有和开源的大语言模型。

例如，来自开放家族的，也来自像 Meta、Hugging Face 或 Mistral 这样的合作伙伴。还有一些工具，能够确保 AI 应用程序的负责任和安全开发，以及用于生成式应用程序的提示工程监控资产。现在，回顾我们的教育初创公司场景，让我们想象一下，经过广泛的研究，我们的初创公司已经探索了当前的大语言模型格局，并为这个独特的场景确定了一些强有力的竞争者。现在，真正的乐趣开始了，因为测试这些模型涉及一个迭代过程，使用实验和度量来确保它们达标，以及他们可以在哪里测试这些模型。他们可以使用 Azure AI Studio 中的模型目录来做到这一点。

Azure AI Studio 通过一个用户友好的界面提供了无缝的体验。所以，在模型目录中你可以做这些事情：你可以通过使用不同的筛选器轻松找到你感兴趣的基础模型，例如，你可以按模型提供商搜索，无论是 Azure、OpenAI、Meta、Hugging Face 等等。

你还可以按推理或微调任务进行搜索。例如，你可以搜索问答、摘要任务，或用于计算机视觉场景的对象检测。

按许可证筛选，例如，你甚至可以当然通过在搜索框中搜索其名称来查找特定模型。嗯，现在一旦你知道，一旦你选择了一个模型，在你继续部署模型本身之前，先对你的模型有所了解总是一个好主意。嗯，模型目录中的模型卡片提供了一个全面的视图，包括对你所选模型的用例和训练数据的详细描述。

对于某些模型，你还可以找到一些代码示例，让我们了解实时推理的输入和输出是什么样的。嗯，此外，有时需要进行一些微调，而 Azure AI Studio 让你能够使用自定义训练数据来提高模型的性能，这适用于模型目录中选定的一部分模型。嗯，就像这张幻灯片中你看到的 Llama 2, 70B 模型。呃，一旦你的模型，你知道的，准备就绪，就可以部署它了，无论是原始的预训练模型还是你最终调整的版本。Azure AI Studio 在部署方面为你提供了保障，对于一些模型，如这里的 Llama 2，嗯，或者通常是 Meta 系列的模型。

你有几个选项。你可以选择标准的部署方式，即实时端点，所以你在你的 Azure 订阅中部署你的模型，并管理用于推理的基础设施。嗯，或者你可以使用最近推出的按需付费（pay-as-you-go）类型的部署。嗯，这意味着你可以消费，例如，Llama 2 模型，就像一个 REST API，而不用关心底层的基础设施，体验类似于使用 Azure OpenAI Service 的 API。嗯，只需通过一个 REST API 来消费它。

这就是我们所说的模型即服务（model as a service）。现在，Azure AI Studio 的另一个有趣功能是模型基准测试。嗯，在这里你基本上可以使用筛选器来比较目录中的不同模型，以确定特定的子集在一些预定义的性能指标上的表现，例如准确性、流畅性、连贯性等等。你可以选择使用几个测试数据集来进行比较。

当谈到将大语言模型部署到生产环境时，企业有多种选择，每种选择都有其自身的复杂性。

当然还有成本和质量水平。让我们深入探讨这些方法，看看哪种方法适合不同的需求。第一种方法是利用带有上下文的提示工程。现在，预训练的大语言模型擅长处理通用语言任务，你只需给它们一个简短的提示，比如一个问题或一个不完整的句子。它们就像魔法一样工作，对吧？我们称之为零样本学习（zero-shot learning），但问题在于：你提供的上下文越多，大语言模型就越能理解你的请求。当你包含详细的示例和请求时，这种方法如果你使用单个示例，则称为单样本学习（one-shot learning），如果你使用多个示例，则称为少样本学习（few-shot learning）。

在对话的情况下，你甚至可以用提示来描述助手的个性。例如，回复的风格和语调，或者将对话历史传递到提示中。这种方法成本效益高，是一个很好的起点。然后，方法二是使用检索增强生成（retrieval-augmented generation），这可以说是一种模式，一种特定的技术——提示工程技术。

事实上，大语言模型有其局限性，因为它们只知道它们被训练过的内容，无法访问训练后的信息或例如公司的私有数据。为了弥补这一差距，我们使用这种模式——检索增强生成，它以文档（CHS）的形式将外部数据添加到你的提示中，有效地扩展了其知识。所以我们通过提示传递数据，但在这样做之前，我们将使用一些搜索管道来查找要添加到我们上下文中的数据。在 Azure 平台上，这是由像 Azure AI Search 这样的向量数据库工具提供支持的。

当你缺乏数据、时间或资源来微调你的大语言模型，但又想提升其性能并最小化不正确信息或有害内容的风险时，RAG 是一种可行的方案。我想在这里介绍的第三种方法是微调。微调是一个为特定任务定制 LLM 的过程，它会生成一个具有更新权重和偏差的新模型，如果你有严格的延迟要求，这使它成为理想选择，所以你不能。

你在提示中确实有一个巨大的上下文，或者你拥有高质量的数据和地面实况标签，并且你可以长期维护它们。呃，相对于 RAG，微调需要额外的计算资源来调整模型的权重。现在，我想说的是，我在这里介绍的这些技术——提示工程、检索增强生成和微调——并非相互排斥；它们是互补的。所以，在某些情况下，你会使用，例如，提示和微调。在其他情况下，你会使用所有这三种技术。

我想介绍的最后一种方法是训练你自己的大语言模型。现在，从头开始训练一个 LLM 是一项巨大的工程，需要海量的数据、高质量的数据、熟练的专业人员和强大的计算能力。你只有在拥有非常特定领域的用例以及大量以领域为中心的数据时，才会考虑这个选项。嗯，在大型语言部署的世界里，没有一刀切的解决方案，所以正确的方法取决于你独特的需求、资源和目标。

我们探讨的这些技术，嗯，正如我所说的，并非总是相互排斥的。所以，在某些情况下，你需要评估，呃，是否需要结合，嗯，其中的几种。嗯，此外，我们在训练和部署方面做出的任何选择，我们都应该对技术的局限性有清醒的认识和透明度，并使用负责任的实践和工具。在下一集中，你会发现这意味着什么，但现在，我想总结一下，Pablo，嘿，我想请你回来，只是为了说声再见。

各位，非常荣幸能和大家更多地谈论生成式 AI。Carlot 也非常了不起，能学到更多东西，我真的很兴奋，你知道的，能和大家更多地交流。我很快也会回来，为大家带来更多关于 AI 初学者的课程。非常感谢，并通过 Microsoft Learn 学习更多。太棒了！谢谢。

大家好，我是 Corey Ster Pace，来自微软的 AI 云技术布道师团队，今天我很荣幸能为大家带来第三课：负责任地使用生成式 AI。你知道，负责任地使用生成式 AI 很重要，无论你只有一个用户，还是一千个用户，或是一百万个用户，它都应该成为你用生成式 AI 构建的一切应用的基石。所以，让我们深入探讨这个概念，并实际看看当我们在为用户构建应用程序时如何应用它。作为本课的介绍，我们将看看为什么我们应该真正优先考虑负责任的 AI。

我的意思是，我们把这节课放在本课程的前面，就是想确保我们所做的一切都围绕着负责-任的 AI。然后，我们将看看负责任 AI 的核心原则，以及它们与生成式 AI 的具体关系。最后，我们将把这些原则付诸实践。有一些原则是很好的，但它们如何实际应用于构建生成式 AI 应用程序呢？谈论我们这节课的目标是很重要的。我们将看到在构建生成式 AI 应用程序时负责任 AI 的重要性。我们将学习如何应用那些负责任 AI 的核心原则，然后最后，我们将带走一些你今天就可以用来将这些原则付诸实践的工具和策略。那么，为什么你应该在微软和本课程中优先考虑负责任的 AI 呢？

我们希望专注于采用以人为本的方法进行应用程序开发，而这实际上归结为用户的最大利益等于你的应用程序的最佳结果。我们意识到，生成式 AI 可以为你的用户创造巨大的价值，但当负责任的 AI 没有得到维护时，这种价值可能会瞬间消失。所以我们需要确保其影响需要监控，并且仅仅有好的意图是不够的。我们不认为人们总是抱着要构建一个不负责任的生成式 AI 应用程序的想法去做事，但我们确实认为，如果你在监控并确保，即使你没有预料到这些事情会发生，你也要有适当的必要系统来提供负责任的体验。所以让我们看看在使用生成式 AI 应用程序时可能遇到的潜在危害。第一个是无根据的输出或错误。这些是最

常见的，比如幻觉或捏造，有时可能是有趣的无稽之谈，也可能是有害的，比如可能在其他系统中使用的失实错误，甚至是回应中的矛盾，无论是在一句话中陈述一个主张，然后在另一句话中反驳它，或者甚至只是向用户呈现完全不相关的信息。下一个就不那么有趣了，它是有害内容。大语言模型可以产生指令，无论是鼓励像自残、仇恨或贬损内容，还是为寻找非法内容或甚至非法行为提供指示。所以我们需要确保我们也要密切关注这一点。最后，是缺乏公平性。我总是告诉我的孩子们生活是不公平的，但生成式 AI 系统绝对应该追求公平。

公平性实际上等同于没有偏见和歧视，所以这意味着要确保输出不会产生任何具有排他性世界观或对任何特定群体有偏见的内容。这一点尤其重要，特别是在我们谈论生成图像或文本时，这与微软自己的负责任 AI 实践非常吻合，无论是公平性、可靠性和安全性、隐私和安全、包容性、透明度还是问责制。那么，既然我们了解了可能出现的潜在危害，我们如何才能真正负责任地使用生成式 AI 呢？

首先要做的是衡量这些潜在的危害。我们鼓励采用类似于软件测试的方法，但也要确保你正在进行像提示测试这样的事情。这意味着你实际上是在追求用户可能使用的各种多样的提示，而这些并不是理想的提示。这些不是你总是期望的，比如用户的“快乐路径”，但重要的是要确保，当你向用户部署应用程序或他们使用你的应用程序时可能出现的任何情况，都包含在你的提示测试中。我们建议你应该从手动开始，这样你可以向大语言模型发送一个提示，接收并评估那个响应，但你也可以通过批量处理这些提示并查看结果来将其扩展到自动化。

手动开始让你能高度接触并非常清楚地了解大语言模型如何响应你的用例。我们今天还将探讨四个缓解层次。一个是在模型层面，构建一个安全系统，使用正确的元提示，最后是在用户体验方面。所以让我们看看这在实践中是如何运作的。首先是模型方面。我喜欢简单地说，正确的模型，正确的用例。嗯，大多数大语言模型可以做很多事情，但其中一些比其他的更专业。你知道，使用最强大的模型并不总是更好。更好的做法是，你或许可以使用像更符合你用例的专业模型。

甚至了解诸如模型温度之类的参数，以及它如何影响响应。甚至可以选择微调或使用一个微调过的模型，这个模型可能更适合你的用लिए case 或你的用户将如何使用你的应用程序。这些都是在模型层面减轻问题的好方法，同样在安全系统中，比如内容过滤。这确保了来自模型的响应会经过它们的过滤器，并且不会呈现任何有害内容。此外，使用像负责任 AI 这样的概念，并对响应建立评分和指标，都是构建良好安全支柱的好方法。

接下来是元提示（meta prompt）。这实际上是我们如何为模型定义行为或规则，以便它如何与用户互动。我们可以通过使用像检索增强生成（retrieval augmented generation）这样的技术，将模型基于上下文或甚至使用可信数据，这在本课程中实际上有涵盖。最后，也是最重要的一点，在用户体验方面，为用户建立关于他们如何与生成式 AI 应用程序或模型互动的透明度非常重要。这包括从用户端设置像约束或输入这样的东西，以限制和减轻可能发生的危害。

他们的提示，然后甚至对响应进行一些输入或输出验证，也是提供良好用户体验和负责任体验的好方法。现在，让我们把这个负责任的 AI 付诸实践。我们已经看过了概念，我们看过了减轻危害的方法，但我们到底该如何开始呢？嗯，在微软内部，我们有像 Azure AI 内容安全这样的东西。这些是 API 端点和工具，允许这些信息在传递给你的用户之前，以一种被扫描的方式呈现。

无论是分析文本，构建像提示护盾（prompt shields）来扫描攻击（在任何用户输入之前，例如 ATT 攻击），还是有根据的检测——确保模型是基于用户提供的源材料的。我们还有负责任 AI 仪表板，它让我们能够基本上对模型的响应方式以及用户与它的互动方式进行评分，并让你对模型随时间推移的表现有一个很好的理解和概览，这不仅在我们第一次为生产环境交付这个生成式 AI 应用程序时非常重要，在第六次、第十次或第一百次时也同样重要。

最后，我们可以通过 Prompt Flow 进行监控来做很多出色的工作。Prompt Flow 是一个开源工具，我们也可以用它来发现和理解传递给用户的响应类型。我们有围绕这方面的指标，无论是连贯性，响应的类型，它是否连贯，是否流畅，有根据性，正如我之前提到的。它是否与实际提示相关？它与其他我们之前见过的提示有多相似？这些都是很好的东西，可以让你有一个概览，并将那些负责任的 AI 实践和原则付诸实践。这就是负责任 AI 课程的全部内容。你可以在 aka.ms/genners 的完整课程中查看更多信息。

嗨，欢迎来到《生成式 AI 初学者》第四课。我叫 Nan Nan，是 AI 布道师团队的高级云技术布道师，我很高兴能和大家谈谈提示工程基础。所以今天我们首先会做一个快速的回顾。如果你一直在关注这个系列，你大概知道大部分术语。我们只是简单地看一下。然后我们会谈谈，如果你想自己开始尝试，可以使用的三个提供商；但今天大部分内容将聚焦于提示工程。

你将学习它是什么，你将学习它为什么重要，你将学习如何进行提示工程，然后我们会让你对如何在实践中建立自己的提示工程思维模式有一个直观的感受。那么让我们开始吧。快速回顾一下：如果你一直在关注这个课程，这些术语你可能已经很熟悉了。什么是提示（prompt）？我们谈论的是生成式 AI 大语言模型。提示就是用户提供的自然语言输入——文本输入。你几乎可以把它想象成用户用来编程模型以执行其意图的方式。所以响应（response）就是模型为了支持用户请求而生成内容的行为。

你可能也听说过“幻觉”（Hallucination）这个词。这是指有时模型生成的响应可能不基于事实，我们稍后会谈到这个。一个基础 LLM，或大语言模型，实际上是这个在海量数据上训练的基础模型。可以把它想象成一个无所不知的通用模型。但有时你想要专门化的模型——那些知道如何很好地完成某项任务的模型。这就是你要寻找的指令调优（instruction-tuned）LLM——那些擅长摘要、翻译或代码生成的模型。那么什么是提示工程（prompt engineering）？提示工程实际上是这样一个过程：你迭代你的提示——也就是你给模型的文本输入，研究响应，然后不断重复，直到响应看起来像你想要的样子。要理解这一点，你需要理解它是如何工作的。那么让我们来看看模型是如何工作的。聊天补全（Chat completion）是这样一个非常基本的事情：你走向模型，那就是你，然后给出你的提示，即你的文本输入，它给你内容，完成。

对吧，但是等等——什么是提示工程？事实证明，有很多小细节你可以调整，这将帮助模型调整它提供给你的响应。例如，你可以有提示模板，用户的输入被放入其中，以提供额外的上下文。你可以查看对话历史；你可以做一些事情，比如检索增强生成和基于数据的 grounding。还有系统上下文和模型参数。所以，通过提示工程，我们真正在看的是如何调整所有这些变量，以便你为你的提示获得最好的响应。但在我们开始并深入细节之前，让我们谈谈你的选择。现在，如果你一直在关注这个课程，有一个入门文件夹会告诉你如何用这些提供商之一来设置自己。你可以选择 OpenAI 或 Hugging Face，或者你可以在 Azure AI 上设置，并使用那里的模型，即 Azure OpenAI 或 Azure AI Studio。今天，大部分时间我们将使用 OpenAI，因为这对你来说非常容易上手，但你可以查看代码仓库以获取使用其他提供商的笔记。一旦你选好了模型，你又有两种选择来尝试。

你可以自己动手做练习：你可以选择无代码选项，你根本不需要懂任何代码。你只需去他们提供的沙盒，或者你可以使用我们给你的、已经设置好你的凭证的笔记本，然后你就可以做交互式编程练习来学习提示工程。今天，我们选择无代码选项，那么现在让我们深入了解吧。你准备好了吗？我们首先需要理解的是，为什么要做提示工程？动机是什么？第一，动机是模型是随机的（stochastic）。这意味着如果你问模型，如果你去找它并给它一个文本输入，不保证它每次都会给你相同的响应。不保证响应是正确的。不保证响应是你所想的那样。让我们看看这意味着什么。所以我们将要做的是，我们将尝试一些这样的练习。

首先，我已经设置好了一些提供商，所以这里是 Hugging Face。我们实际上要用 Hugging Chat，这是他们的开源聊天实现，里面内置了一个模型，现在我们用的是 Microsoft 53。我也用 OpenAI 的 playground 设置好了，另一方面，我也有 Azure OpenAI。所以我们将从给它们完全相同的提示开始。让我们看看会发生什么。所以我要进入这里然后问，“让我们从 Hugging Face 开始”，然后说，“嘿，告诉我关于元素镓（gallium）的事情”，你会看到它给了你一个恰当的响应。它告诉你它是一种化学元素。但看看它给你的是什么；它像是一个多段落的回复，对吧？所以你去找这个提供商，这个模型，你得到了这个。