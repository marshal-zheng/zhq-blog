---
author: ZHQ
pubDatetime: 2025-01-05T10:45:00+08:00
title: '生成式AI介绍'
featured: false
draft: false
tags:
  - 'ai-for-beginners'
description: '介绍生成式AI的相关概念'
---

# 第一课：生成式 AI 和大语言模型简介

---

大家好，欢迎来到《生成式 AI 入门》系列课程的第一课。本课程基于 GitHub 上的同名开源课程，您可以在屏幕上看到的链接中找到它。我是 Carlotta Castello，微软的一名云技术布道师，专注于人工智能技术。在本视频中，我将向大家介绍生成式 AI 和大语言模型。

大语言模型代表了 AI 技术的巅峰，突破了曾经被认为不可能的界限。它们攻克了许多老旧语言模型难以解决的挑战，在各种任务中达到了人类水平的表现。它们有多种能力和应用，但在本课程中，我们将通过一个虚构的初创公司（我们称之为“我们的”初创公司）来探讨大语言模型如何彻底改变教育。我们的初创公司在教育领域工作，其宏大的使命是在全球范围内提高学习的可及性，确保每个学习者都能根据自己的需求获得公平的教育学习体验。

在本课程中，我们将深入探讨我们的初-创公司如何利用生成式 AI 的力量，在教育领域开启新的可能性。我们还将研究他们如何应对这项技术带来的社会影响和技术限制等不可避免的挑战。

首先，让我们来定义一些我们将在整个课程中使用的基本概念。尽管生成式 AI 在近几年才引起广泛关注，我们可以这样讲，在过去几年里，在做的各位几乎无时无刻、无处不在地听到生成式 AI。但其实这项技术已经酝酿了几十年，其起源可以追溯到 20 世纪 50 年代和 60 年代。早期的 AI 原型包括一些生硬的的聊天机器人，它们依赖于专家维护的知识库。这些聊天机器人根据用户输入中的关键词生成回应，但使用后会就发现这种方法存在输出可扩展性的限制。

一个重要的转折点出现在 20 世纪 90 年代，当时统计学方法被应用于文本分析，这催生了<span className="text-orange-500">机器学习算法</span>。这些算法可以从数据中学习模式，无需显式编程，从而使机器能够模拟人类语言理解，为我们今天所知的 AI 铺平了道路。

近年来，硬件技术的不断进步极大推动了先进机器学习算法的发展，尤其是神经网络。这些创新不仅提升了自然语言处理的能力，还使得机器能够更好地理解句子中单词的上下文关系。这一突破为虚拟助手的出现奠定了坚实基础。

进入 21 世纪后，虚拟助手在理解人类语言、识别用户需求以及采取相应行动方面取得了显著进步。例如，它们能够通过预设脚本回答问题，或与第三方服务集成以满足用户的各种需求。

![生成式AI示意图](https://cdn.jsdelivr.net/gh/marshal-zheng/images-hosting@main/images/6ZyOgB.jpg)

于是我们来到了**生成式 AI**，它是**深度学习**的一个子集。经过几十年的 AI 研究，一种名为 **Transformer** 的新模型架构应运而生。Transformer 可以处理更长的文本序列作为输入，并通过<span className="text-orange-500">注意力机制聚焦于</span>最相关的信息，而不受其具体顺序的影响。如今，通常被称为**大语言模型**的生成式 AI 模型，都是建立在 Transformer 架构之上的，这也就是 **GPT** 中“T”所代表的含义。这类模型会在海量数据（如书籍、文章和网站）上进行训练，具备极强的适应能力，能够胜任多种任务，并生成语法规范且富有创造力的文本。

在进一步探索大语言模型的工作原理时，我们需要理解像 OpenAI 的 GPT 这类模型背后的核心机制。其中，**分词 (tokenization)** 是必须掌握的重要概念。大语言模型通常<span className="text-orange-500">以文本作为输入</span>，<span className="text-orange-500">并生成文本作为输出</span>。不过，模型在处理数字时远比直接处理原始文本更高效，因此会将文本转换为数字编码后再进行处理。

这就用到了分词器。它会将文本提示(Prompt)拆分为**词元 (token)**，以便模型能够逐步预测并补全下一个词元。每个模型都有一个最大词元窗口长度(maxTokens)，输入和输出的词元数量不仅影响模型的处理能力，也直接关系到使用成本——许多模型的定价就是按词元数量计算的。因此，<span className="text-orange-500">分词</span>在大语言模型和生成式 AI 的应用中至关重要。

一个词元（Token）本质上是文本中的一个基本单元，其长度可以变化，通常由一个或多个字符组成。分词器的主要任务是将输入文本拆分为一个词元数组，这些词元可以是单个汉字、英文单词、标点符号，甚至是部分单词。拆分后的词元会被映射为**词元索引**，即每个词元都对应一个唯一的整数编码。这种编码方式让模型能够高效地处理和理解文本内容，<span className="text-red-500">因为神经网络更擅长处理数字而非原始文本。</span>

举例来说，句子“生成式AI很有趣”经过分词器处理后，可能会被拆分为 ["生成", "式", "AI", "很", "有趣"] 这样的词元数组。每个词元会被分配一个索引(及词元ID)，如 [1023, 56, 2048, 77, 8901]。模型在训练和推理过程中，实际操作的就是这些索引而不是原始文本。

不同的分词器采用不同的拆分策略，例如字节对分（Byte Pair Encoding, BPE）、按词或子词分割等。选择合适的分词方式不仅能够提升模型对文本的理解能力和生成质量，还会影响模型的运行效率和使用成本。深入理解分词和词元索引的原理，有助于更好地掌握大语言模型的工作机制，从而优化提示设计和输出控制，提升实际应用效果。

现在，让我们进一步了解模型在处理包含 n 个词元的输入序列时如何预测输出词元。每个模型都有一个最大内容窗口长度（maxTokens），决定了它一次能处理的词元数量。当模型预测下一个词元时，它实际上只生成一个词元作为输出。随后，<span className="text-orange-500">这个新词元会被加入到输入序列的末尾</span>，形成一个扩展的窗口。模型会以这种方式不断迭代，每次都将最新生成的词元并入输入，逐步生成更长的文本。这种机制不仅提升了生成内容的连贯性，还能更好地保持上下文相关性，使模型能够输出完整的句子甚至多句话。
> 以下是以“生成式AI是什么？”为输入，模型一步步生成输出的例子：
>
> 输入（Prompt）：  
> 生成式AI是什么？
>
> 处理过程：
> 1. 首先，分词器将输入文本“生成式AI是什么？”拆分为词元，比如 ["生成", "式", "AI", "是", "什么", "？"]。
> 2. 每个词元会被映射为唯一的数字 ID，例如 [1023, 56, 2048, 77, 8901, 5]（仅为示例，实际 ID 由分词器决定）。
> 3. 模型实际接收的是这个数字 ID 数组作为输入。
> 4. 模型预测下一个最可能的词元 ID，比如 12（对应“它”）。
> 5. 把新生成的词元 ID 加到输入后面，变成 [1023, 56, 2048, 77, 8901, 5, 12]。
> 6. 模型继续预测下一个词元 ID，比如 34（对应“是”），依次类推，直到生成完整的答案。
> 7. 最后，所有生成的词元 ID 会被分词器转换回文本，得到最终输出。  
> 这样一步步，模型可能最终生成完整的回答
>
> 输出（Completion）：  
> 它是一种能够根据输入自动生成文本、图片或其他内容的人工智能技术。
>
> 这个过程就是模型每次只生成一个词元，然后把新词元加到输入后面，继续预测，直到输出完整的答案。

现在，让我们深入了解模型的词元选择过程。每次生成输出时，模型会根据当前文本序列，计算每个可能词元在下一个位置出现的概率。这些概率分布是通过模型在大量训练数据上的学习获得的。值得注意的是，<span className="text-red-500">模型并不总是选择概率最高的词元作为输出。为了增强生成内容的多样性和创造性，</span> 模型在选择时会引入一定的随机性。这种机制使得同样的输入在不同生成过程中可能得到不同的输出，从而提升了生成式 AI 的灵活性和表现力。

这意味着，即使输入完全相同，模型每次生成的输出也可能有所不同。正是这种随机性，使得生成式 AI 能够创作出更具创造力和吸引力的文本内容，提升了交互体验和文本的多样性。

我们之前提到，大语言模型的核心能力是根据自然语言输入生成新的文本。那么，具体来说，模型处理的输入和输出分别是什么？在实际应用中，模型的输入通常被称为**提示（prompt）**，而输出则被称为**补全（completion）**。<span className="text-orange-500"></span>，最终形成完整的回答或文本。这一机制使得大语言模型能够灵活地响应各种指令，实现从文本续写到问题解答等多种功能。

让我们通过 OpenAI ChatGPT Playground 来演示提示（Prompt）与补全（Completion）的实际应用。在我们设定的教育场景中，一个提示通常包含明确的指令，说明我们希望模型输出的内容类型。例如，我们可以要求模型为初中生设计一份关于中国古代诗人李白及其诗歌的作业，并包含四个开放式问题。模型会根据提示生成相应的输出，内容与我们的要求高度契合，充分展示了生成式 AI 在教育领域的实用价值。

因此，模型不仅可以生成带有问题的作业，还能应对多样化的提示。例如，有些提示以对话形式提出，比如我们询问“李白是谁？为什么他是中国古代重要的诗人？”，模型会据此生成详细的答案。另一类提示则是提供一段待补全的文本开头，模型能够自动续写并补全整段内容，实现智能写作辅助。这些应用场景充分展现了生成式 AI 在文本生成和交互方面的灵活性与强大能力。

以上示例仅为基础演示，旨在帮助大家理解生成式 AI 的核心机制和应用潜力。实际上，大语言模型的能力远不止于此。它们能够在教育、医疗、创意写作等众多领域发挥作用，极大地拓展了人工智能的应用边界。通过这些简单的例子，我们可以初步感受到生成式模型在提升学习体验、个性化教学和智能辅助等方面的巨大价值。未来，随着技术不断进步，生成式 AI 将为各行各业带来更多创新可能。

今天的课程就到这里。下一课我们将深入介绍生成式 AI 模型的不同类型，并探讨如何进行测试、迭代和性能优化。同时，我们还会讲解如何比较各类模型，帮助大家为具体应用场景选择最合适的解决方案。